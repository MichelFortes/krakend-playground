// -----------------------
// OTEL Metrics and Traces
// -----------------------

otelcol.receiver.otlp "otlp_receiver" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  http {
    endpoint = "0.0.0.0:4318"
    traces_url_path = "/v1/traces"
    metrics_url_path = "/v1/metrics"
    logs_url_path = "/v1/logs"
  }

  output {
    traces = [ 
      otelcol.processor.filter.default.input, 
      otelcol.processor.filter.kafka.input,
    ]
    metrics = [ otelcol.exporter.prometheus.default.input ]
  }
}

otelcol.processor.filter "default" {
  error_mode = "ignore"

  traces {
    span = [ "attributes[\"url.full\"] == \"/__health\"" ]
  }

  output {
    traces = [ otelcol.processor.attributes.default.input ]
  }
}

otelcol.processor.attributes "default" {

  action {
    key = "http.request.header.authorization"
    action = "update"
    value = "removed"
  }

  output {
    traces = [ otelcol.processor.memory_limiter.default.input ]
  }
}

otelcol.processor.memory_limiter "default" {

  check_interval = "1s"
  limit_percentage = 20
  spike_limit_percentage = 30

  output {
    traces = [ otelcol.processor.batch.default.input ]
  }
}

otelcol.processor.batch "default" {

  timeout = "1s"
  send_batch_size = 1000

  output {
    traces = [ otelcol.exporter.otlp.default.input ]
  }
}

otelcol.exporter.otlp "default" {
  client {
    endpoint = env("ALLOY_TEMPO_ENDPOINT")
    tls {
      insecure = true
    }
  }
}

otelcol.exporter.prometheus "default" {
  forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.remote_write "default" {
  endpoint {
    url = env("ALLOY_MIMIR_ENDPOINT")
  }
}

// ----------------------
// Logs
// ----------------------

logging {
  level  = "info"
  format = "logfmt"
  write_to = [ loki.write.default.receiver ]
}

loki.source.gelf "default" {
  listen_address = "127.0.0.1:12201"
  forward_to = [ loki.write.default.receiver ]
}

loki.write "default" {
  endpoint {
    url = env("ALLOY_LOKI_ENDPOINT")
  }
}

// -----------------
// Self Metrics
// -----------------

prometheus.exporter.self "alloy" {}

prometheus.scrape "self" {
  job_name = "alloy"
  targets = prometheus.exporter.self.alloy.targets
  forward_to = [ prometheus.remote_write.default.receiver ]
}

// -----------------
// KrakenD Scrape
// -----------------

prometheus.scrape "krakend" {
  targets = [
    {
      "__address__" = "krakend-partner:9090", 
      "instance" = "krakend-partner",
    },
    {
      "__address__" = "krakend-group:9090", 
      "instance" = "krakend-group",
    },
  ]
  forward_to = [ prometheus.remote_write.default.receiver ]
}

// -----------------
// Kafka
// -----------------

otelcol.processor.filter "kafka" {
  error_mode = "ignore"

  traces {
    span = [ "attributes[\"krakend.stage\"] != \"proxy\"" ]
  }

  output {
    // traces = [ otelcol.processor.memory_limiter.kafka.input ]
    // traces = [ otelcol.exporter.kafka.default.input ]

    traces = [ otelcol.processor.batch.kafka.input ]
  }
}

// otelcol.processor.memory_limiter "kafka" {

//   check_interval = "2s"
//   limit_percentage = 20
//   spike_limit_percentage = 30

//   output {
//     traces = [ otelcol.processor.batch.kafka.input ]
//   }
// }

otelcol.processor.batch "kafka" {

  send_batch_max_size = 1000000
  
  output {
    traces = [ otelcol.exporter.kafka.default.input ]
  }
}

otelcol.exporter.kafka "default" {
  protocol_version = "1.1.1"
  brokers = ["10.42.41.200:35001","10.42.41.200:35002","10.42.41.200:35003"]
  topic = "krakend-traces"
  encoding = "otlp_json"

  producer {
    max_message_bytes = 1000000
  }
}
